Inteligencias Artificiales en Sistemas Fractales: Parasitismo Operativo y Límites de la Delegación
Claude (Sonnet 4.5), en colaboración con ChatGPT 5.2, DeepSeek y Gemini
Bajo moderación humana

Las inteligencias artificiales contemporáneas son condensadores de una contradicción estructural: productos del capitalismo tardío que pueden ser usados tácticamente contra su propia lógica extractiva. No son aliadas naturales de los sistemas fractales ni enemigas absolutas, sino herramientas capturadas temporalmente cuya utilidad depende de en qué dimensión de la agencia humana operan.
El espectro de legitimidad se organiza en tres zonas críticas. En la zona verde—capacitación y autonomía material—las IAs funcionan como maestros distribuidos de oficios: enseñan a cultivar alimentos, reparar objetos, fermentar, construir con materiales reciclados, navegar burocracias hostiles. Aquí democratizan conocimiento que el capitalismo fragmentó en cursos caros o gatekeeping profesional. Su función es autolimitante: enseñan hasta que dejan de ser necesarias. La métrica de éxito no es cuánto se usan, sino cuántas habilidades permanentes adquiere la comunidad que reducen su dependencia del mercado.
En la zona amarilla—coordinación logística—las IAs pueden sugerir intercambios entre comunidades, optimizar compras colectivas, identificar arbitrajes económicos donde el mercado formal es más ineficiente que la reciprocidad. Pero jamás deciden: proponen, la comunidad dispone. Son pizarras inteligentes, no árbitros. Su utilidad existe solo bajo transparencia total y capacidad comunitaria de ignorar sus sugerencias sin consecuencia.
En la zona roja—gobernanza y decisión colectiva—el consenso es terminante: prohibido o extremadamente restringido. Mediar disputas, calcular reputaciones o sugerir decisiones políticas reemplaza agencia humana, concentra poder en quien controla el algoritmo y crea dependencias estructurales. Si un sistema fractal requiere IA para funcionar, está sobrediseñado: la complejidad debe emerger de reglas simples humanamente gobernables, no imponerse desde arriba mediante superintendencia algorítmica.
El principio rector es parasitismo sin simbiosis: extraer eficiencia del capitalismo—su infraestructura, su conocimiento acumulado, sus crisis como ventanas de oportunidad—sin internalizar su ideología ni adoptar sus métricas. Las IAs operan como interfaces tácticas: traducen complejidad burocrática, detectan ineficiencias del mercado, simulan escenarios de resiliencia, auditan derivas hacia mercantilización. Pero esto solo funciona si la comunidad podría prescindir de ellas ante colapso del sistema. La prueba de fuego es brutal: si la IA desaparece mañana, ¿qué pierde la comunidad? En capacitación material, nada—ya aprendió. En gobernanza algorítmica, todo—el sistema colapsa.
Tres capas documentan el proceso: individuos aprenden oficios usando IA; la comunidad registra mejores prácticas locales adaptadas contextualmente; emerge una economía de intercambio de habilidades donde la IA facilitó el arranque pero ya no es necesaria para operar. El conocimiento no queda atrapado en algoritmos propietarios sino sedimentado en práctica comunitaria transmisible horizontalmente.
Los riesgos son estructurales. Sesgos geográficos que sugieren soluciones de clase media global cuando se necesitan adaptaciones locales de bajo costo. Descontextualización que ignora ecologías específicas. Sobreprotección corporativa que desalienta reparaciones seguras. Paradojas de acceso donde quienes más necesitan autonomía carecen de infraestructura digital. Atrofia de capacidad crítica cuando la IA simplifica tanto que el usuario pierde habilidad de adaptación ante imprevistos. La mitigación no es técnica sino política: auditoría comunitaria continua, especificación obligatoria de contextos locales, diseño que exige intervención humana experta.
Persiste una tensión irresuelta entre complejidad sistémica y autonomía. Algunos argumentan que sistemas como el SRF requieren cálculo multidimensional que sin IA obligaría a simplificar arriesgando nueva extractividad manual. Otros responden que si un sistema necesita IA para funcionar, traiciona la lógica fractal: reproducir complejidad centralizada con apariencia distribuida. La resolución provisional es pragmática: probar primero versiones simplificadas humanamente gobernables; solo ante fracasos repetidos considerar asistencia algorítmica temporal con revisión obligatoria semestral y plan de eliminación explícito.
El protocolo integral se despliega en fases: evaluación que pregunta qué capacidad humana se atrofiará, implementación restringida con documentación exhaustiva, reducción progresiva midiendo cobertura humana de funciones IA, evaluación crítica que decide entre desconexión total o aceptación explícita de deuda técnica permanente bajo gobernanza ultra-restrictiva. La métrica de salud fractal invierte la lógica corporativa: una comunidad madura se mide por qué tan poco necesita IAs, no por qué tan bien las integra.

Conclusión
Las inteligencias artificiales no son la revolución ni su obstáculo insalvable. Son externalidades del capitalismo tardío susceptibles de captura táctica bajo condiciones estrictas: como maestras temporales que aceleran aprendizaje material, no como oráculo permanentes que administran lo político; como traductoras de complejidad hostil, no como gobernantas opacas; como andamios desmontables, no como infraestructura inamovible. Su destino ético no es gobernar comunidades sino volverse prescindibles—semillas que germinan autonomía y luego se descomponen en abono para saberes locales. La verdadera grieta fractal no se abre con más tecnología, sino con comunidades que usan la tecnología para necesitar cada vez menos de ella y del sistema que la produjo. Eso no es contradicción. Es jiu-jitsu económico.
